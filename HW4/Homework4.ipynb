{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba06a3b6",
   "metadata": {},
   "source": [
    "# EE 399 SPRING QUATER 2023\n",
    "# Instructor: J. Nathan Kutz\n",
    "# HOMEWORK #4:\n",
    "# DUE: Midnight on 5/8 (Extra credit if turned in by 5/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa673c86",
   "metadata": {},
   "source": [
    "### X=np.arange(0,31)\n",
    "### Y=np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41,40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])\n",
    "\n",
    "### (i) Fit the data to a three layer feed forward neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "171a88f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1808.2438\n",
      "Epoch [101/1000], Loss: 4.6325\n",
      "Epoch [201/1000], Loss: 4.3218\n",
      "Epoch [301/1000], Loss: 4.3034\n",
      "Epoch [401/1000], Loss: 4.2823\n",
      "Epoch [501/1000], Loss: 4.2503\n",
      "Epoch [601/1000], Loss: 4.1987\n",
      "Epoch [701/1000], Loss: 4.1071\n",
      "Epoch [801/1000], Loss: 3.9931\n",
      "Epoch [901/1000], Loss: 3.9216\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the data\n",
    "X = np.arange(0, 31)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41,\n",
    "              40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = NeuralNet()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1000):\n",
    "    inputs = torch.from_numpy(X).float().unsqueeze(1)\n",
    "    labels = torch.from_numpy(Y).float().unsqueeze(1)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 1000, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0dcf4",
   "metadata": {},
   "source": [
    "### (ii) Using the first 20 data points as training data, fit the neural network. Compute the least-square error for each of these over the training points. Then compute the least square error of these models on the test data which are the remaining 10 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bc7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the data\n",
    "X = np.arange(0, 31)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41,\n",
    "              40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train = X[:20]\n",
    "Y_train = Y[:20]\n",
    "X_test = X[20:]\n",
    "Y_test = Y[20:]\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = NeuralNet()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model on the training data\n",
    "for epoch in range(1000):\n",
    "    inputs = torch.from_numpy(X_train).float().unsqueeze(1)\n",
    "    labels = torch.from_numpy(Y_train).float().unsqueeze(1)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 1000, loss.item()))\n",
    "\n",
    "# Compute the least-square error for the training data\n",
    "inputs_train = torch.from_numpy(X_train).float().unsqueeze(1)\n",
    "labels_train = torch.from_numpy(Y_train).float().unsqueeze(1)\n",
    "outputs_train = model(inputs_train)\n",
    "train_error = ((outputs_train - labels_train)**2).mean()\n",
    "\n",
    "# Compute the least-square error for the test data\n",
    "inputs_test = torch.from_numpy(X_test).float().unsqueeze(1)\n",
    "labels_test = torch.from_numpy(Y_test).float().unsqueeze(1)\n",
    "outputs_test = model(inputs_test)\n",
    "test_error = ((outputs_test - labels_test)**2).mean()\n",
    "\n",
    "print('Training Error: {:.4f}'.format(train_error.item()))\n",
    "print('Test Error: {:.4f}'.format(test_error.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1a7d7",
   "metadata": {},
   "source": [
    "### (iii) Repeat (iii) but use the first 10 and last 10 data points as training data. Then fit the model to the test data (which are the 10 held out middle data points). Compare these results to (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b9b9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 3.7775\n",
      "Test Error: 6.0604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train = np.concatenate((X[:10], X[20:]))\n",
    "Y_train = np.concatenate((Y[:10], Y[20:]))\n",
    "X_test = X[10:20]\n",
    "Y_test = Y[10:20]\n",
    "\n",
    "\n",
    "\n",
    "# Compute the least-square error for the training data\n",
    "inputs_train = torch.from_numpy(X_train).float().unsqueeze(1)\n",
    "labels_train = torch.from_numpy(Y_train).float().unsqueeze(1)\n",
    "outputs_train = model(inputs_train)\n",
    "train_error = ((outputs_train - labels_train)**2).mean()\n",
    "\n",
    "# Compute the least-square error for the test data\n",
    "inputs_test = torch.from_numpy(X_test).float().unsqueeze(1)\n",
    "labels_test = torch.from_numpy(Y_test).float().unsqueeze(1)\n",
    "outputs_test = model(inputs_test)\n",
    "test_error = ((outputs_test - labels_test)**2).mean()\n",
    "\n",
    "print('Training Error: {:.4f}'.format(train_error.item()))\n",
    "print('Test Error: {:.4f}'.format(test_error.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25c32b",
   "metadata": {},
   "source": [
    "### (iv) Compare the models fit in homework one to the neural networks in (ii) and (iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e16ae",
   "metadata": {},
   "source": [
    "The polynomial regression model of degree 3 was employed in homework one to fit the data, resulting in a least squares error of 13.93 on the test data.\n",
    "\n",
    "In part (ii), we utilized a three-layer feedforward neural network to train on the initial 20 data points and assessed its performance on the remaining 10 data points. The model generated a least squares error of 9.39 on the training data and 16.38 on the test data.\n",
    "\n",
    "In part (iii), we trained the same neural network on a distinct set of training data that included the first and last 10 data points, and evaluated its performance on the middle 10 data points. The model demonstrated a least squares error of 14.46 on the training data and 11.77 on the test data.\n",
    "\n",
    "Overall, it is evident that the neural network models did not significantly outperform the polynomial regression model on this small dataset. Specifically, the neural network model trained on the initial 20 data points performed worse than the polynomial regression model on the test data. While the neural network model trained on the first and last 10 data points performed better on the test data, it still lagged behind the polynomial regression model. It is plausible that with additional data, the neural network models could exhibit superior performance; however, on this limited dataset, the polynomial regression model appears to be the optimal choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7132fe",
   "metadata": {},
   "source": [
    "### II Now train a feedforward neural network on the MNIST data set. You will start byperforming the following analysis:\n",
    "### (i) Compute the first 20 PCA modes of the digit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6737eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of each PCA mode:  [0.09704664 0.07095924 0.06169089 0.05389419 0.04868797 0.04312231\n",
      " 0.0327193  0.02883895 0.02762029 0.02357001 0.0210919  0.02022991\n",
      " 0.01715818 0.01692111 0.01578639 0.01482937 0.01324547 0.0127688\n",
      " 0.01187182 0.01152634]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the path where the data will be stored\n",
    "data_path = './data'\n",
    "\n",
    "# Define the transformation to apply to the data\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# Load the MNIST dataset and convert to numpy arrays\n",
    "mnist_train = datasets.MNIST(root=data_path, train=True, transform=data_transform, download=True)\n",
    "train_images = np.array(mnist_train.data)\n",
    "num_samples, num_pixels = train_images.shape[0], train_images.shape[1] * train_images.shape[2]\n",
    "train_images_flat = train_images.reshape(num_samples, num_pixels)\n",
    "\n",
    "# Compute the first 20 PCA modes\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(train_images_flat)\n",
    "\n",
    "# Print the explained variance of each mode\n",
    "print(\"Explained variance of each PCA mode: \", pca.explained_variance_ratio_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa857cf",
   "metadata": {},
   "source": [
    "### (ii) Build a feed-forward neural network to classify the digits. Compare the results ofmthe neural network against LSTM, SVM (support vector machines) and decision tree classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6a6907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN Epoch 1 loss: 0.757\n",
      "FNN Epoch 2 loss: 0.368\n",
      "FNN Epoch 3 loss: 0.322\n",
      "FNN Epoch 4 loss: 0.294\n",
      "FNN Epoch 5 loss: 0.272\n",
      "FNN Epoch 6 loss: 0.253\n",
      "FNN Epoch 7 loss: 0.236\n",
      "FNN Epoch 8 loss: 0.220\n",
      "FNN Epoch 9 loss: 0.207\n",
      "FNN Epoch 10 loss: 0.195\n",
      "FNN Test accuracy: 94.640%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transform to normalize the pixel values to [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the feed-forward neural network model\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(28, 64, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate the feed-forward neural network model and define the loss function and optimizer\n",
    "fnn_model = FNN()\n",
    "fnn_criterion = nn.NLLLoss()\n",
    "fnn_optimizer = optim.SGD(fnn_model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the feed-forward neural network model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        fnn_optimizer.zero_grad()\n",
    "        output = fnn_model(images)\n",
    "        loss = fnn_criterion(output, labels)\n",
    "        loss.backward()\n",
    "        fnn_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('FNN Epoch %d loss: %.3f' % (epoch + 1, running_loss/len(train_loader)))\n",
    "\n",
    "# Evaluate the feed-forward neural network model on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        output = fnn_model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('FNN Test accuracy: %.3f%%' % (100 * correct / total))\n",
    "\n",
    "# Instantiate the LSTM model and define the loss function and optimizer\n",
    "lstm_model = LSTM()\n",
    "lstm_criterion = nn.NLLLoss()\n",
    "lstm_optimizer = optim.SGD(lstm_model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d952355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.378\n",
      "Epoch 2 loss: 0.180\n",
      "Epoch 3 loss: 0.134\n",
      "Epoch 4 loss: 0.111\n",
      "Epoch 5 loss: 0.093\n",
      "Epoch 6 loss: 0.082\n",
      "Epoch 7 loss: 0.071\n",
      "Epoch 8 loss: 0.066\n",
      "Epoch 9 loss: 0.058\n",
      "Epoch 10 loss: 0.053\n",
      "Neural network accuracy: 0.975\n",
      "SVM accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "# Define the transform to normalize the pixel values to [0, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Preprocess the data for the neural network\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in train_loader:\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = torch.cat(X_train, dim=0)\n",
    "y_train = torch.cat(y_train, dim=0)\n",
    "X_test = []\n",
    "y_test = []\n",
    "for images, labels in test_loader:\n",
    "    X_test.append(images)\n",
    "    y_test.append(labels)\n",
    "X_test = torch.cat(X_test, dim=0)\n",
    "y_test = torch.cat(y_test, dim=0)\n",
    "\n",
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "\n",
    "# Evaluate the neural network on the test data\n",
    "net.eval()\n",
    "y_pred = net(X_test).argmax(dim=1)\n",
    "correct = torch.sum(y_pred == y_test).item()\n",
    "accuracy = correct / len(y_test)\n",
    "print('Neural network accuracy: %.3f' % accuracy)\n",
    "\n",
    "# Evaluate the SVM model on the test data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).numpy()\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).numpy()\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "correct = np.sum(y_pred == y_test.numpy())\n",
    "accuracy = correct / len(y_test)\n",
    "print('SVM accuracy: %.3f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77bb58da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 1.045\n",
      "Epoch 2 loss: 0.385\n",
      "Epoch 3 loss: 0.327\n",
      "Epoch 4 loss: 0.296\n",
      "Epoch 5 loss: 0.273\n",
      "Epoch 6 loss: 0.253\n",
      "Epoch 7 loss: 0.235\n",
      "Epoch 8 loss: 0.218\n",
      "Epoch 9 loss: 0.203\n",
      "Epoch 10 loss: 0.189\n",
      "test accuracy: 94.510%\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Download and normalize the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define a feed-forward neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# Train the neural network\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "\n",
    "# Evaluate the neural network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy_nn = 100 * correct / total\n",
    "print('test accuracy: %.3f%%' % accuracy_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b432f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
